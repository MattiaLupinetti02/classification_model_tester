{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "208fc4a2-b525-4013-8115-4f8b8b114750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, GridSearchCV, cross_val_score\n",
    "from typing import Dict, List\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score,f1_score\n",
    "from functools import partial\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re\n",
    "import seaborn as sns\n",
    "from model_tester import ModelTester\n",
    "from custom_best_param_calulator import CustomBestParamCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f95c805b-d8e5-4d99-848d-db1a5d262723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./performance_exp1.csv\")\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f52b6888-d474-4518-be7f-6d4a2d6625fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_params(s):\n",
    "    return re.sub(r'\\s*:\\s*np\\.float64\\(.*?\\)\\s*\\}?$', '', s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "542204db-068c-43ef-8aac-d97f10be8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hyperparameters'] = df['Hyperparameters'].apply(extract_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72c8fc8f-4e4e-4e6f-a4c1-0c4fd2d464ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyper = df.groupby([\"Model\", \"Experiment\"])[[\"Hyperparameters\"]].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c7e6294-c836-456f-95a5-9ea0bff014ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.drop(index=hyper[hyper[\"Experiment\"].str.startswith(\"specific\")].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04087167-5f92-47f1-beae-4b4651a3283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_overall = hyper[hyper[\"Experiment\"].str.endswith(\"overall\")]\n",
    "hyper_ADASYN = hyper[hyper[\"Experiment\"].str.startswith(\"overall_ADASYN\")]\n",
    "hyper_SMOTE = hyper[hyper[\"Experiment\"].str.startswith(\"overall_SMOTE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ce9686b-0e38-4d53-bd50-5470e8df2332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"criterion\": \"gini\", \"max_depth\": 5, \"min_sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"bootstrap\": false, \"criterion\": \"entropy\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"criterion\": \"friedman_mse\", \"learning_rate\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"C\": 10000000.0, \"max_iter\": 70, \"multi_class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"criterion\": \"gini\", \"max_depth\": 10, \"min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVC</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"C\": 1, \"degree\": 2, \"gamma\": \"scale\", \"kerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"gamma\": 0, \"learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Experiment  \\\n",
       "0       DecisionTreeClassifier    overall   \n",
       "6         ExtraTreesClassifier    overall   \n",
       "12  GradientBoostingClassifier    overall   \n",
       "18          LogisticRegression    overall   \n",
       "24      RandomForestClassifier    overall   \n",
       "30                         SVC    overall   \n",
       "36               XGBClassifier    overall   \n",
       "\n",
       "                                      Hyperparameters  \n",
       "0   {\"criterion\": \"gini\", \"max_depth\": 5, \"min_sam...  \n",
       "6   {\"bootstrap\": false, \"criterion\": \"entropy\", \"...  \n",
       "12  {\"criterion\": \"friedman_mse\", \"learning_rate\":...  \n",
       "18  {\"C\": 10000000.0, \"max_iter\": 70, \"multi_class...  \n",
       "24  {\"criterion\": \"gini\", \"max_depth\": 10, \"min_sa...  \n",
       "30  {\"C\": 1, \"degree\": 2, \"gamma\": \"scale\", \"kerne...  \n",
       "36  {\"colsample_bytree\": 0.8, \"gamma\": 0, \"learnin...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4ba0f20-ce37-4aba-8973-59210e246f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_overall.loc[:,\"Model\"] = [i+\"()\" for i in hyper_overall[\"Model\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2c09e71-f43f-4709-978d-3cf59913c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_SMOTE.loc[:,\"Model\"] = [i+\"()\" for i in hyper_SMOTE[\"Model\"] ]\n",
    "hyper_ADASYN.loc[:,\"Model\"] = [i+\"()\" for i in hyper_ADASYN[\"Model\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dc3308f-a340-47d5-a284-d7b4d1370dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22b92a18-0e7a-4830-8ae7-a237f9b87db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [eval(i) for i in hyper_overall[\"Model\"]]\n",
    "SMOTE_model = [eval(i) for i in hyper_SMOTE[\"Model\"]]\n",
    "ADASYN_model = [eval(i) for i in hyper_ADASYN[\"Model\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3843173-eba2-4f94-821e-228e56258eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_dt_model', 'smote_dt_model', 'adasyn_dt_model']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = [hyper_overall,hyper_SMOTE,hyper_ADASYN]\n",
    "models = {\"base_dt_model\":[],\"smote_dt_model\":[],\"adasyn_dt_model\":[]}\n",
    "list_dt = list(models.keys())\n",
    "list_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c175bba9-5368-409c-b523-a98b7ada28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for data_model in model_data:\n",
    "    for i in data_model.index:\n",
    "        model_name = data_model.loc[i, \"Model\"]\n",
    "        \n",
    "            \n",
    "        params_str = data_model.loc[i, \"Hyperparameters\"]\n",
    "\n",
    "        mdl = eval(model_name)  # allowed_models = {\"DecisionTreeClassifier\": DecisionTreeClassifier, ...}\n",
    "        if type(mdl) == type(SVC()):\n",
    "            mdl.set_params(probability=True)\n",
    "        if type(mdl) == type(LogisticRegression()):\n",
    "            mdl.set_params(max_iter=1000000)\n",
    "            # Converte iperparametri in dizionario\n",
    "            params = json.loads(params_str.strip(\"'\").strip('\"'))\n",
    "            params.pop(\"max_iter\")\n",
    "            params.pop(\"multi_class\")\n",
    "        else:\n",
    "            params = json.loads(params_str.strip(\"'\").strip('\"'))\n",
    "        \n",
    "        \n",
    "        mdl.set_params(**params)\n",
    "        # Imposta iperparametri\n",
    "        \n",
    "\n",
    "        # Salva il modello\n",
    "        models[list_dt[j]].append(mdl)\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6856a04-0b89-4c93-8729-61c4dfd17bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>smoker</th>\n",
       "      <th>ex-smoker</th>\n",
       "      <th>FC</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>oxigen_therapy</th>\n",
       "      <th>6MWT</th>\n",
       "      <th>BT</th>\n",
       "      <th>alert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>104.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.3</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>114.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.2</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.5</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>YELLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>F</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>140.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ox</td>\n",
       "      <td>False</td>\n",
       "      <td>36.5</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.5</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>M</td>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>85.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>F</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender  Age  smoker  ex-smoker     FC   SpO2 oxigen_therapy   6MWT    BT  \\\n",
       "0        F   43   False      False  104.0   94.0             no  False  36.0   \n",
       "1        M   79   False       True   85.0   89.0             no  False  36.3   \n",
       "2        M   81    True      False  114.0   86.0             no  False  36.2   \n",
       "3        M   81   False      False   92.0   86.0             no  False  36.5   \n",
       "4        F   48   False      False   87.0   93.0             no  False  36.0   \n",
       "..     ...  ...     ...        ...    ...    ...            ...    ...   ...   \n",
       "595      F  101   False      False   89.0  100.0             no  False  36.0   \n",
       "596      F   14   False      False  140.0   91.0             ox  False  36.5   \n",
       "597      F   71   False       True   80.0   99.0             no  False  36.5   \n",
       "598      M  106   False      False   85.0   91.0             no  False  36.0   \n",
       "599      F   36   False      False   92.0   99.0             no  False  36.0   \n",
       "\n",
       "      alert  \n",
       "0     GREEN  \n",
       "1     GREEN  \n",
       "2       RED  \n",
       "3       RED  \n",
       "4    YELLOW  \n",
       "..      ...  \n",
       "595   GREEN  \n",
       "596     RED  \n",
       "597   GREEN  \n",
       "598   GREEN  \n",
       "599   GREEN  \n",
       "\n",
       "[600 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_new = pd.read_csv(\"../dati_dott_fedele/dati_m2_incolonnati.csv\")\n",
    "dt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6e85303-13d9-40b9-bd50-d924e2a10f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\"\"\"\n",
    "models = {\n",
    "    LogisticRegression(max_iter=10000): \n",
    "        {'C': [0.1, 1, 10], 'max_iter': [100,200]},\n",
    "    \n",
    "    SVC(kernel='linear'): \n",
    "        {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},    \n",
    "}\n",
    "\"\"\"\n",
    "# Dizionario di modelli con iperparametri per GridSearchCV\n",
    "#, tree_method=\"gpu_hist\"\n",
    "modelli = {\n",
    "\n",
    "        # XGBClassifier\n",
    "     XGBClassifier(eval_metric=\"logloss\"): { \n",
    "        'n_estimators': [50,75],\n",
    "        'max_depth': [5,6],  \n",
    "        'learning_rate': [ 0.3,0.4],\n",
    "        'subsample': [0.8,0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "        'reg_lambda': [0, 0.1, 1, 10],   # L2 regularization (lambda)\n",
    "        'reg_alpha': [0, 0.1, 1, 10],    # L1 regularization (alpha)\n",
    "        'gamma': [0, 0.1, 0.5, 1]   \n",
    "    },    \n",
    "   \n",
    "\n",
    "    # GradientBoostingClassifier\n",
    "    GradientBoostingClassifier(): { \n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'n_estimators': [25,50],\n",
    "        'max_depth': [8,10], \n",
    "        'max_depth': [3, 5, 10], \n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "        'learning_rate': [ 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'subsample': [0.7],\n",
    "        'criterion': ['friedman_mse'],  \n",
    "        'criterion': ['friedman_mse', 'mse'],\n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_split': [2,3],  \n",
    "        'min_samples_leaf': [1, 2, 4,5],\n",
    "        'min_samples_leaf': [ 4,5]\n",
    "    },\n",
    "\n",
    "    # LogisticRegression\n",
    "    LogisticRegression(max_iter=1000000): { \n",
    "        'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "        'C': np.logspace(-3, 9, 7),\n",
    "        'max_iter': np.arange(50, 100, 10),\n",
    "        'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "        'tol': np.logspace(-5, -1, 5),\n",
    "        'multi_class': ['ovr', 'multinomial']\n",
    "    },\n",
    "\n",
    "    # SVC\n",
    "    SVC(): { \n",
    "        'kernel': ['rbf', 'poly', 'linear'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'degree': [2, 3, 4, 5]  \n",
    "    },\n",
    "\n",
    "    # DecisionTreeClassifier\n",
    "    DecisionTreeClassifier(): { \n",
    "        'max_depth': [5, 10, 15], \n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "\n",
    "    # RandomForestClassifier\n",
    "    RandomForestClassifier(n_estimators=100): { \n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'max_depth': [5, 10, 20], \n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "\n",
    "    # ExtraTreesClassifier\n",
    "    ExtraTreesClassifier(n_estimators=100): { \n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'max_depth': [5, 10, 20], \n",
    "        'min_samples_split': [2, 5, 10], \n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "}\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "resampling_methods = [\n",
    "    SMOTE(random_state=42, sampling_strategy='auto'),\n",
    "    ADASYN(random_state=42, sampling_strategy='minority')\n",
    "]\n",
    "metrics = {\"accuracy\":accuracy_score,\"precision\":precision_score,\"recall\":recall_score,\"f1-score\":f1_score}\n",
    "\n",
    "tester = ModelTester(modelli,metrics,dt_new.copy(),\"alert\",resamplingMethods=resampling_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c6afa37-f2ed-4205-ae54-58f42b2b9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, scoring):\n",
    "    results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
    "    return {metric: results[f'test_{metric}'].mean() for metric in scoring}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0968bef-f930-4f04-9f55-0656d6ec483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tester.data_handler.encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f321585b-d8ac-49df-a93c-1ed9837203cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "datasets[\"base_dt\"] = pd.concat([tester.data_handler.encoded_data,pd.DataFrame(tester.data_handler.y_encoded, columns=[tester.target])],axis=1)\n",
    "for name,dt in tester.data_handler.resampled_data_dict.items():\n",
    "    datasets[name.lower()+\"_dt\"] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3012ec41-bb65-4e7b-8429-76ff828bae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment on the base_dt\n",
      "          precision_GREEN  precision_RED  precision_YELLOW  recall_GREEN  \\\n",
      "Voting           0.895215       0.770500          0.539872      0.950300   \n",
      "Stacking         0.915936       0.793362          0.565363      0.944745   \n",
      "\n",
      "          recall_RED  recall_YELLOW  f1-score_GREEN  f1-score_RED  \\\n",
      "Voting      0.785897       0.441667        0.921237      0.764158   \n",
      "Stacking    0.809615       0.512121        0.929321      0.789246   \n",
      "\n",
      "          f1-score_YELLOW  \n",
      "Voting           0.473077  \n",
      "Stacking         0.529294  \n",
      "experiment on the smote_dt\n",
      "          precision_GREEN  precision_RED  precision_YELLOW  recall_GREEN  \\\n",
      "Voting           0.948069       0.952431          0.870985      0.906006   \n",
      "Stacking         0.934862       0.958022          0.902593      0.933709   \n",
      "\n",
      "          recall_RED  recall_YELLOW  f1-score_GREEN  f1-score_RED  \\\n",
      "Voting      0.947372       0.903679        0.923429      0.949011   \n",
      "Stacking    0.961186       0.895270        0.933123      0.958927   \n",
      "\n",
      "          f1-score_YELLOW  \n",
      "Voting           0.882951  \n",
      "Stacking         0.896075  \n",
      "experiment on the adasyn_dt\n",
      "          precision_GREEN  precision_RED  precision_YELLOW  recall_GREEN  \\\n",
      "Voting           0.924856       0.907691          0.829432      0.889339   \n",
      "Stacking         0.921957       0.908452          0.850242      0.897673   \n",
      "\n",
      "          recall_RED  recall_YELLOW  f1-score_GREEN  f1-score_RED  \\\n",
      "Voting      0.736538       0.901032        0.904964      0.790146   \n",
      "Stacking    0.785256       0.895476        0.907289      0.827027   \n",
      "\n",
      "          f1-score_YELLOW  \n",
      "Voting           0.861105  \n",
      "Stacking         0.868889  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "custom = CustomBestParamCalculator(tester.modelList,tester.metrics,tester.data_handler.get_label_mapping(),cv=10,searcher_class=GridSearchCV)\n",
    "\n",
    "for name,mod in models.items():\n",
    "    print(\"experiment on the \" + name.split(\"_model\")[0])\n",
    "    keys = [str(m) for m in mod]\n",
    "    mod_dict = dict(zip(keys,mod))\n",
    "\n",
    "\n",
    "    models_voting = []\n",
    "    for m_name, m  in mod_dict.items():\n",
    "        models_voting.append((m_name,m))\n",
    "    \n",
    "    #final_estimator = LogisticRegression(max_iter=200)\n",
    "    \n",
    "    final_estimator = LogisticRegression(max_iter = 10000000)\n",
    "    \n",
    "    # =====================\n",
    "    # 3. Definizione ensemble\n",
    "    # =====================\n",
    "    voting_clf = VotingClassifier(estimators=models_voting, voting='soft')\n",
    "    \n",
    "    \n",
    "    \n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=models_voting,\n",
    "        final_estimator=final_estimator\n",
    "    )\n",
    "    \n",
    "# =====================\n",
    "# 4. Cross Validation con metriche multiple\n",
    "# =====================\n",
    "    scoring = ['precision_macro', 'recall_macro', 'f1_macro']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # 5. Esecuzione\n",
    "    # =====================\n",
    "    results = {\n",
    "        \"Voting\": evaluate_model(voting_clf, datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], custom.make_metrics_by_labels(avg=\"macro\")),\n",
    "        \"Stacking\": evaluate_model(stacking_clf,  datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], custom.make_metrics_by_labels(avg=\"macro\"))\n",
    "    }\n",
    "    \n",
    "    # =====================\n",
    "    # 6. Risultati\n",
    "    # =====================\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fbb7c26-e838-4504-ace7-17488ec0f106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment on the base_dt\n",
      "          accuracy  precision_macro  recall_macro  f1_macro\n",
      "Voting    0.825000         0.748220      0.739209  0.732893\n",
      "Stacking  0.831667         0.768862      0.750864  0.749601\n",
      "experiment on the smote_dt\n",
      "          accuracy  precision_macro  recall_macro  f1_macro\n",
      "Voting    0.922562         0.926975      0.922648  0.922379\n",
      "Stacking  0.930878         0.933223      0.931006  0.930467\n",
      "experiment on the adasyn_dt\n",
      "          accuracy  precision_macro  recall_macro  f1_macro\n",
      "Voting    0.871429         0.889673      0.835686  0.846410\n",
      "Stacking  0.892857         0.901007      0.876109  0.881244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "for name,mod in models.items():\n",
    "    print(\"experiment on the \" + name.split(\"_model\")[0])\n",
    "    keys = [str(m) for m in mod]\n",
    "    mod_dict = dict(zip(keys,mod))\n",
    "\n",
    "\n",
    "    models_voting = []\n",
    "    for m_name, m  in mod_dict.items():\n",
    "        models_voting.append((m_name,m))\n",
    "    \n",
    "    #final_estimator = LogisticRegression(max_iter=200)\n",
    "    \n",
    "    final_estimator = LogisticRegression(max_iter = 10000000)\n",
    "    \n",
    "    # =====================\n",
    "    # 3. Definizione ensemble\n",
    "    # =====================\n",
    "    voting_clf = VotingClassifier(estimators=models_voting, voting='soft')\n",
    "    \n",
    "    \n",
    "    \n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=models_voting,\n",
    "        final_estimator=final_estimator\n",
    "    )\n",
    "    \n",
    "# =====================\n",
    "# 4. Cross Validation con metriche multiple\n",
    "# =====================\n",
    "    scoring = ['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # 5. Esecuzione\n",
    "    # =====================\n",
    "    results = {\n",
    "        \"Voting\": evaluate_model(voting_clf, datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], scoring),\n",
    "        \"Stacking\": evaluate_model(stacking_clf,  datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], scoring)\n",
    "    }\n",
    "    \n",
    "    # =====================\n",
    "    # 6. Risultati\n",
    "    # =====================\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "do_da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
