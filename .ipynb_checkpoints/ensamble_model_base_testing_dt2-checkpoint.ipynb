{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208fc4a2-b525-4013-8115-4f8b8b114750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve, GridSearchCV, cross_val_score\n",
    "from typing import Dict, List\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score,f1_score\n",
    "from functools import partial\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re\n",
    "import seaborn as sns\n",
    "from model_tester import ModelTester\n",
    "from custom_best_param_calulator import CustomBestParamCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95c805b-d8e5-4d99-848d-db1a5d262723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./performance_exp2.csv\")\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52b6888-d474-4518-be7f-6d4a2d6625fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_params(s):\n",
    "    return re.sub(r'\\s*:\\s*np\\.float64\\(.*?\\)\\s*\\}?$', '', s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542204db-068c-43ef-8aac-d97f10be8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hyperparameters'] = df['Hyperparameters'].apply(extract_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c8fc8f-4e4e-4e6f-a4c1-0c4fd2d464ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyper = df.groupby([\"Model\", \"Experiment\"])[[\"Hyperparameters\"]].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7e6294-c836-456f-95a5-9ea0bff014ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper.drop(index=hyper[hyper[\"Experiment\"].str.startswith(\"specific\")].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04087167-5f92-47f1-beae-4b4651a3283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_overall = hyper[hyper[\"Experiment\"].str.endswith(\"overall\")]\n",
    "hyper_ADASYN = hyper[hyper[\"Experiment\"].str.startswith(\"overall_ADASYN\")]\n",
    "hyper_SMOTE = hyper[hyper[\"Experiment\"].str.startswith(\"overall_SMOTE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce9686b-0e38-4d53-bd50-5470e8df2332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"criterion\": \"gini\", \"max_depth\": 10, \"min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"bootstrap\": false, \"criterion\": \"gini\", \"max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"criterion\": \"friedman_mse\", \"learning_rate\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"C\": 1000000000.0, \"max_iter\": 90, \"multi_cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"criterion\": \"gini\", \"max_depth\": 10, \"min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVC</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"C\": 1, \"degree\": 2, \"gamma\": \"scale\", \"kerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>overall</td>\n",
       "      <td>{\"colsample_bytree\": 1.0, \"gamma\": 1, \"learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Experiment  \\\n",
       "0       DecisionTreeClassifier    overall   \n",
       "6         ExtraTreesClassifier    overall   \n",
       "12  GradientBoostingClassifier    overall   \n",
       "18          LogisticRegression    overall   \n",
       "24      RandomForestClassifier    overall   \n",
       "30                         SVC    overall   \n",
       "36               XGBClassifier    overall   \n",
       "\n",
       "                                      Hyperparameters  \n",
       "0   {\"criterion\": \"gini\", \"max_depth\": 10, \"min_sa...  \n",
       "6   {\"bootstrap\": false, \"criterion\": \"gini\", \"max...  \n",
       "12  {\"criterion\": \"friedman_mse\", \"learning_rate\":...  \n",
       "18  {\"C\": 1000000000.0, \"max_iter\": 90, \"multi_cla...  \n",
       "24  {\"criterion\": \"gini\", \"max_depth\": 10, \"min_sa...  \n",
       "30  {\"C\": 1, \"degree\": 2, \"gamma\": \"scale\", \"kerne...  \n",
       "36  {\"colsample_bytree\": 1.0, \"gamma\": 1, \"learnin...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ba0f20-ce37-4aba-8973-59210e246f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_overall.loc[:,\"Model\"] = [i+\"()\" for i in hyper_overall[\"Model\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c09e71-f43f-4709-978d-3cf59913c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_SMOTE.loc[:,\"Model\"] = [i+\"()\" for i in hyper_SMOTE[\"Model\"] ]\n",
    "hyper_ADASYN.loc[:,\"Model\"] = [i+\"()\" for i in hyper_ADASYN[\"Model\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc3308f-a340-47d5-a284-d7b4d1370dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b92a18-0e7a-4830-8ae7-a237f9b87db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [eval(i) for i in hyper_overall[\"Model\"]]\n",
    "SMOTE_model = [eval(i) for i in hyper_SMOTE[\"Model\"]]\n",
    "ADASYN_model = [eval(i) for i in hyper_ADASYN[\"Model\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3843173-eba2-4f94-821e-228e56258eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_dt_model', 'smote_dt_model', 'adasyn_dt_model']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = [hyper_overall,hyper_SMOTE,hyper_ADASYN]\n",
    "models = {\"base_dt_model\":[],\"smote_dt_model\":[],\"adasyn_dt_model\":[]}\n",
    "list_dt = list(models.keys())\n",
    "list_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c175bba9-5368-409c-b523-a98b7ada28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for data_model in model_data:\n",
    "    for i in data_model.index:\n",
    "        model_name = data_model.loc[i, \"Model\"]\n",
    "        \n",
    "            \n",
    "        params_str = data_model.loc[i, \"Hyperparameters\"]\n",
    "\n",
    "        mdl = eval(model_name)  # allowed_models = {\"DecisionTreeClassifier\": DecisionTreeClassifier, ...}\n",
    "        if type(mdl) == type(SVC()):\n",
    "            mdl.set_params(probability=True)\n",
    "        if type(mdl) == type(LogisticRegression()):\n",
    "            mdl.set_params(max_iter=1000000)\n",
    "            # Converte iperparametri in dizionario\n",
    "            params = json.loads(params_str.strip(\"'\").strip('\"'))\n",
    "            params.pop(\"max_iter\")\n",
    "            params.pop(\"multi_class\")\n",
    "        else:\n",
    "            params = json.loads(params_str.strip(\"'\").strip('\"'))\n",
    "        \n",
    "        \n",
    "        mdl.set_params(**params)\n",
    "        # Imposta iperparametri\n",
    "        \n",
    "\n",
    "        # Salva il modello\n",
    "        models[list_dt[j]].append(mdl)\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6856a04-0b89-4c93-8729-61c4dfd17bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>smoker</th>\n",
       "      <th>ex-smoker</th>\n",
       "      <th>previous_alert</th>\n",
       "      <th>FC</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>oxigen_therapy</th>\n",
       "      <th>6MWT</th>\n",
       "      <th>BT</th>\n",
       "      <th>alert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BLANK</td>\n",
       "      <td>104.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>BLANK</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.3</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>BLANK</td>\n",
       "      <td>114.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.2</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BLANK</td>\n",
       "      <td>92.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.5</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>BLANK</td>\n",
       "      <td>87.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>YELLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>101</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>RED</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ox</td>\n",
       "      <td>False</td>\n",
       "      <td>36.5</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>71</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.5</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>106</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>GREEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Gender  smoker  ex-smoker previous_alert     FC   SpO2  \\\n",
       "0     43      F   False      False          BLANK  104.0   94.0   \n",
       "1     79      M   False       True          BLANK   85.0   89.0   \n",
       "2     81      M    True      False          BLANK  114.0   86.0   \n",
       "3     81      M   False      False          BLANK   92.0   86.0   \n",
       "4     48      F   False      False          BLANK   87.0   93.0   \n",
       "..   ...    ...     ...        ...            ...    ...    ...   \n",
       "595  101      F   False      False            RED   89.0  100.0   \n",
       "596   14      F   False      False          GREEN  140.0   91.0   \n",
       "597   71      F   False       True          GREEN   80.0   99.0   \n",
       "598  106      M   False      False          GREEN   85.0   91.0   \n",
       "599   36      F   False      False          GREEN   92.0   99.0   \n",
       "\n",
       "    oxigen_therapy   6MWT    BT   alert  \n",
       "0               no  False  36.0   GREEN  \n",
       "1               no  False  36.3   GREEN  \n",
       "2               no  False  36.2     RED  \n",
       "3               no  False  36.5     RED  \n",
       "4               no  False  36.0  YELLOW  \n",
       "..             ...    ...   ...     ...  \n",
       "595             no  False  36.0   GREEN  \n",
       "596             ox  False  36.5     RED  \n",
       "597             no  False  36.5   GREEN  \n",
       "598             no  False  36.0   GREEN  \n",
       "599             no  False  36.0   GREEN  \n",
       "\n",
       "[600 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_new = pd.read_csv(\"../dati_dott_fedele/dati_m2_incolonnati_v2.csv\")\n",
    "dt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6e85303-13d9-40b9-bd50-d924e2a10f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\"\"\"\n",
    "models = {\n",
    "    LogisticRegression(max_iter=10000): \n",
    "        {'C': [0.1, 1, 10], 'max_iter': [100,200]},\n",
    "    \n",
    "    SVC(kernel='linear'): \n",
    "        {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},    \n",
    "}\n",
    "\"\"\"\n",
    "# Dizionario di modelli con iperparametri per GridSearchCV\n",
    "#, tree_method=\"gpu_hist\"\n",
    "modelli = {\n",
    "\n",
    "        # XGBClassifier\n",
    "     XGBClassifier(eval_metric=\"logloss\"): { \n",
    "        'n_estimators': [50,75],\n",
    "        'max_depth': [5,6],  \n",
    "        'learning_rate': [ 0.3,0.4],\n",
    "        'subsample': [0.8,0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "        'reg_lambda': [0, 0.1, 1, 10],   # L2 regularization (lambda)\n",
    "        'reg_alpha': [0, 0.1, 1, 10],    # L1 regularization (alpha)\n",
    "        'gamma': [0, 0.1, 0.5, 1]   \n",
    "    },    \n",
    "   \n",
    "\n",
    "    # GradientBoostingClassifier\n",
    "    GradientBoostingClassifier(): { \n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'n_estimators': [25,50],\n",
    "        'max_depth': [8,10], \n",
    "        'max_depth': [3, 5, 10], \n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "        'learning_rate': [ 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 1.0],\n",
    "        'subsample': [0.7],\n",
    "        'criterion': ['friedman_mse'],  \n",
    "        'criterion': ['friedman_mse', 'mse'],\n",
    "        'min_samples_split': [2, 5, 10],  \n",
    "        'min_samples_split': [2,3],  \n",
    "        'min_samples_leaf': [1, 2, 4,5],\n",
    "        'min_samples_leaf': [ 4,5]\n",
    "    },\n",
    "\n",
    "    # LogisticRegression\n",
    "    LogisticRegression(max_iter=1000000): { \n",
    "        'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "        'C': np.logspace(-3, 9, 7),\n",
    "        'max_iter': np.arange(50, 100, 10),\n",
    "        'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "        'tol': np.logspace(-5, -1, 5),\n",
    "        'multi_class': ['ovr', 'multinomial']\n",
    "    },\n",
    "\n",
    "    # SVC\n",
    "    SVC(): { \n",
    "        'kernel': ['rbf', 'poly', 'linear'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'degree': [2, 3, 4, 5]  \n",
    "    },\n",
    "\n",
    "    # DecisionTreeClassifier\n",
    "    DecisionTreeClassifier(): { \n",
    "        'max_depth': [5, 10, 15], \n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "\n",
    "    # RandomForestClassifier\n",
    "    RandomForestClassifier(n_estimators=100): { \n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'max_depth': [5, 10, 20], \n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "\n",
    "    # ExtraTreesClassifier\n",
    "    ExtraTreesClassifier(n_estimators=100): { \n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'max_depth': [5, 10, 20], \n",
    "        'min_samples_split': [2, 5, 10], \n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "}\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "resampling_methods = [\n",
    "    SMOTE(random_state=42, sampling_strategy='auto'),\n",
    "    ADASYN(random_state=42, sampling_strategy='minority')\n",
    "]\n",
    "metrics = {\"accuracy\":accuracy_score,\"precision\":precision_score,\"recall\":recall_score,\"f1-score\":f1_score}\n",
    "\n",
    "tester = ModelTester(modelli,metrics,dt_new.copy(),\"alert\",resamplingMethods=resampling_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c6afa37-f2ed-4205-ae54-58f42b2b9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, scoring):\n",
    "    results = cross_validate(model, X, y, cv=10, scoring=scoring)\n",
    "    return {metric: results[f'test_{metric}'].mean() for metric in scoring}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0968bef-f930-4f04-9f55-0656d6ec483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tester.data_handler.encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f321585b-d8ac-49df-a93c-1ed9837203cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "datasets[\"base_dt\"] = pd.concat([tester.data_handler.encoded_data,pd.DataFrame(tester.data_handler.y_encoded, columns=[tester.target])],axis=1)\n",
    "for name,dt in tester.data_handler.resampled_data_dict.items():\n",
    "    datasets[name.lower()+\"_dt\"] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3012ec41-bb65-4e7b-8429-76ff828bae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment on the base_dt\n",
      "          precision_GREEN  precision_RED  precision_YELLOW  recall_GREEN  \\\n",
      "Voting           0.893130       0.800069          0.601810      0.939264   \n",
      "Stacking         0.896221       0.821785          0.562864      0.939339   \n",
      "\n",
      "          recall_RED  recall_YELLOW  f1-score_GREEN  f1-score_RED  \\\n",
      "Voting      0.843590       0.468939        0.914176      0.810293   \n",
      "Stacking    0.809615       0.496212        0.916263      0.802969   \n",
      "\n",
      "          f1-score_YELLOW  \n",
      "Voting           0.498821  \n",
      "Stacking         0.519360  \n",
      "experiment on the smote_dt\n",
      "          precision_GREEN  precision_RED  precision_YELLOW  recall_GREEN  \\\n",
      "Voting           0.963877       0.958663          0.885078      0.905931   \n",
      "Stacking         0.961841       0.970520          0.933625      0.939039   \n",
      "\n",
      "          recall_RED  recall_YELLOW  f1-score_GREEN  f1-score_RED  \\\n",
      "Voting      0.961186       0.928378        0.932429      0.958986   \n",
      "Stacking    0.977928       0.944595        0.949514      0.973999   \n",
      "\n",
      "          f1-score_YELLOW  \n",
      "Voting           0.903578  \n",
      "Stacking         0.937753  \n",
      "experiment on the adasyn_dt\n",
      "          precision_GREEN  precision_RED  precision_YELLOW  recall_GREEN  \\\n",
      "Voting           0.942599       0.918492           0.84960      0.908784   \n",
      "Stacking         0.929146       0.913997           0.89159      0.917042   \n",
      "\n",
      "          recall_RED  recall_YELLOW  f1-score_GREEN  f1-score_RED  \\\n",
      "Voting      0.719872       0.929365        0.922760      0.786238   \n",
      "Stacking    0.819872       0.923651        0.921061      0.855326   \n",
      "\n",
      "          f1-score_YELLOW  \n",
      "Voting           0.885620  \n",
      "Stacking         0.905532  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "custom = CustomBestParamCalculator(tester.modelList,tester.metrics,tester.data_handler.get_label_mapping(),cv=10,searcher_class=GridSearchCV)\n",
    "\n",
    "for name,mod in models.items():\n",
    "    print(\"experiment on the \" + name.split(\"_model\")[0])\n",
    "    keys = [str(m) for m in mod]\n",
    "    mod_dict = dict(zip(keys,mod))\n",
    "\n",
    "\n",
    "    models_voting = []\n",
    "    for m_name, m  in mod_dict.items():\n",
    "        models_voting.append((m_name,m))\n",
    "    \n",
    "    #final_estimator = LogisticRegression(max_iter=200)\n",
    "    \n",
    "    final_estimator = LogisticRegression(max_iter = 10000000)\n",
    "    \n",
    "    # =====================\n",
    "    # 3. Definizione ensemble\n",
    "    # =====================\n",
    "    voting_clf = VotingClassifier(estimators=models_voting, voting='soft')\n",
    "    \n",
    "    \n",
    "    \n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=models_voting,\n",
    "        final_estimator=final_estimator\n",
    "    )\n",
    "    \n",
    "# =====================\n",
    "# 4. Cross Validation con metriche multiple\n",
    "# =====================\n",
    "    scoring = ['precision_macro', 'recall_macro', 'f1_macro']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # 5. Esecuzione\n",
    "    # =====================\n",
    "    results = {\n",
    "        \"Voting\": evaluate_model(voting_clf, datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], custom.make_metrics_by_labels(avg=\"macro\")),\n",
    "        \"Stacking\": evaluate_model(stacking_clf,  datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], custom.make_metrics_by_labels(avg=\"macro\"))\n",
    "    }\n",
    "    \n",
    "    # =====================\n",
    "    # 6. Risultati\n",
    "    # =====================\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fbb7c26-e838-4504-ace7-17488ec0f106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment on the base_dt\n",
      "          accuracy  precision_macro  recall_macro  f1_macro\n",
      "Voting    0.825000         0.761153       0.74387  0.733646\n",
      "Stacking  0.828333         0.764472       0.74997  0.748016\n",
      "experiment on the smote_dt\n",
      "          accuracy  precision_macro  recall_macro  f1_macro\n",
      "Voting    0.929035         0.933066      0.929079  0.928785\n",
      "Stacking  0.950221         0.952452      0.950150  0.950114\n",
      "experiment on the adasyn_dt\n",
      "          accuracy  precision_macro  recall_macro  f1_macro\n",
      "Voting    0.895181         0.910261      0.858204  0.870172\n",
      "Stacking  0.907085         0.911483      0.885768  0.892684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "for name,mod in models.items():\n",
    "    print(\"experiment on the \" + name.split(\"_model\")[0])\n",
    "    keys = [str(m) for m in mod]\n",
    "    mod_dict = dict(zip(keys,mod))\n",
    "\n",
    "\n",
    "    models_voting = []\n",
    "    for m_name, m  in mod_dict.items():\n",
    "        models_voting.append((m_name,m))\n",
    "    \n",
    "    #final_estimator = LogisticRegression(max_iter=200)\n",
    "    \n",
    "    final_estimator = LogisticRegression(max_iter = 10000000)\n",
    "    \n",
    "    # =====================\n",
    "    # 3. Definizione ensemble\n",
    "    # =====================\n",
    "    voting_clf = VotingClassifier(estimators=models_voting, voting='soft')\n",
    "    \n",
    "    \n",
    "    \n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=models_voting,\n",
    "        final_estimator=final_estimator\n",
    "    )\n",
    "    \n",
    "# =====================\n",
    "# 4. Cross Validation con metriche multiple\n",
    "# =====================\n",
    "    scoring = ['accuracy','precision_macro', 'recall_macro', 'f1_macro']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # =====================\n",
    "    # 5. Esecuzione\n",
    "    # =====================\n",
    "    results = {\n",
    "        \"Voting\": evaluate_model(voting_clf, datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], scoring),\n",
    "        \"Stacking\": evaluate_model(stacking_clf,  datasets[name.split(\"_model\")[0]].drop(\"alert\",axis=1), datasets[name.split(\"_model\")[0]][\"alert\"], scoring)\n",
    "    }\n",
    "    \n",
    "    # =====================\n",
    "    # 6. Risultati\n",
    "    # =====================\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72dc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "do_da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
